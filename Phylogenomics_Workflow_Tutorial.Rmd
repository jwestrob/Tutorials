# Phylogenomics Workflow Tutorial
### v 0.1.0

Hello there! This is the first iteration of a tutorial on how to use my phylogenomics pipeline (powered by Anvi'o and ITOL).

First, let's address a key question: why would you want to do this?

  - You have an insatiable desire to create phylogenetic trees
  - You have some unknown genomes that you want to get a taxonomic placement for
  - You want to pull out ribosomal genes from lots of genomes at once
  - You want to experience sassy error messages from Anvi'o

If any of those apply to you, read on! If not... do what you like, I suppose.

Please note that the following tutorial only applies to Unix-based systems. If you don't have a Unix-based system, consider getting one.

---

## Installation

There are two possible situations if you're reading this.

1. You are working at Pitt and have access to Microbiome01.

2. You don't have access to the Pitt cluster.

If the first one applies to you, either use my account or talk to Kelvin. (Emailing me would be preferable in this case if it's not running globally yet; I can give you the info you need to run this)

If the second one applies to you, we're going to do some installation.

If you don't have Python installed, go ahead and install that (instructions are distribution-specific, and I leave it in your capable hands).

First, go [here](https://www.anaconda.com/download/#linux) to download the Anaconda installer. Please ensure you download the version that fits the Python version you have.

Second, go to wherever you downloaded the file and perform the following:

```{r, engine='bash', install_conda}
bash Anaconda[VERSION NAME].sh
```

Then follow the helpful instructions. The wonderful thing about Anaconda is that this will work fine even if you're on a cluster where you don't have sudo access. Trying to install software without sudo can be aggravating, and conda tends to get past that particular hurdle very well.

This will create a local installation; if you're on a cluster with multiple users, this will not give them access to it!! In order to do so you will likely have to do a couple things, like:

 - modify the conda directory (which you will specify upon install) to be accessible to all users if necessary.
 - Take the line generated by conda in your .bashrc (in your home directory; try using 'ls -a' to find it) and have other users put it in their .bashrc files.

Congratulations! From this point on installing things should be easy. Make sure you can run conda:

```{r, engine='bash', check_conda}
conda --version
```

If everything's good, proceed. Otherwise... try again or contact me with your error. Google is also a reliable friend in instances like these, and you will likely be able to solve this most quickly by googling it. Please try that before contacting me or I will tell you to google it.

### Installing Anvi'o
Watch this.

```{r, engine='bash', install_anvio}
conda create -n anvio4 -c bioconda -c conda-forge python=3 anvio=4
```

Boom.

### Installing iqtree

And again, bask in the glory of easy software installation.

```{r, engine='bash', install_anvio}
conda install -c bioconda iqtree
```

Ta-dah!


---

## Basic overview and outline

The phylogenomics workflow I've "developed" (I put together other people's software; this is just how to do it) is fairly straightforward, though it does involve a couple of steps.
The main purpose behind it was to create a database to use to generate taxonomic placements for unknown MAGs from a sample of Sage Grouse secum. We got several MAGs out of my assembly pipeline (https://github.com/jwestrob/Metaxas; if you're trying to use this please let me know so I can help) but had no way of doing taxonomic ID for any of them, save for one _Megamonas_ MAG.

Essentially, Anvi'o has several suites of HMMs for bacterial and archaeal single-copy genes, as well as ribosomal RNA genes. The basic gist of what I do here is covered in great detail here as well: http://merenlab.org/2017/06/07/phylogenomics/ I highly recommend you look there for a good understanding of all the things Anvi'o can do, as well as bash tips and tricks. The folks at the Meren lab know exactly what they're doing. This is kind of a stripped-down, streamlined version of what that page describes, with examples of how to go about adding to the database and understanding what it is and does.

---

Please note that I have made several scripts to make this process a lot easier. I'm going to show you precisely how to go about using them with a specific tutorial (TODO: ADD LINK TO EXAMPLE DOC).

The scripts are hosted at https://github.com/jwestrob/Script_Toybox. If you are going to proceed with the tutorial, please clone this repository onto your computer as so:

```{r, engine='bash', clone-toybox}
git clone https://github.com/jwestrob/Script_Toybox.git
```

From here on out, I will refer to the directory where you placed this repository as "SCRIPTS". I recommend putting it someplace convenient, such as in your home directory, so you can access it with something like "~/scripts". Also, I always rename the directory to "scripts" so I don't have to type out Script_Toybox. Do what you like.

Scripts we’ll be using:

- SCRIPTS/run_anvio_dbandstats.py : Takes all .fa files in a directory and runs everything to generate good contigs databases for you. Just runs in the local directory. If you need to use it in subdirectories, do a symbolic link (ln -s ~/scripts/run_anvio_dbandstats.py). Make sure to go in and modify the number of threads (set to 4 by default) to the number available on your system.

- SCRIPTS/get_concatenated_proteins.sh : Takes all the contigs databases you’ve generated and gets a concatenated alignment of Ribosomal LSU Proteins 1-6, both in nucleotide and amino acid format. FOR BACTERIA ONLY!!!! Modifying it to use Archaeal SCGs or Ribosomal RNAs is as easy as changing “--hmm-source” to “Rinke_et_al” or “Ribosomal_RNAs”, respectively.

- SCRIPTS/get_extended_proteins.sh : Does the same as the above script, but instead of Large Subunit proteins 1-6, it uses all the ribosomal proteins in the Campbell et al. HMM suite (49 in total).




# REMINDER

You will always forget to do this. Make sure to execute the command

```{r, engine='bash', source_activate_anvio}
source activate anvio4
```

before you start doing anything with Anvi'o. This activates the virtual environment for Anvi'o, hosted from within Anaconda.

Once a genome has been converted into a 'contigs database' via the command

```{r, engine='bash', anvi-profile}
```
